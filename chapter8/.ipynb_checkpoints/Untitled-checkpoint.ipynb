{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "image_size = 32\n",
    "num_channels = 3\n",
    "num_categories = 10\n",
    "num_filters = 32\n",
    "filter_size = 5\n",
    "num_epochs = 200\n",
    "batch_size = 10\n",
    "num_batches = int(50000/batch_size)\n",
    "keep_prob = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CIFAR Training Data\n",
    "train_data = None\n",
    "train_labels = None\n",
    "for file_index in range(5):\n",
    "    \n",
    "    train_file = open('C:/Users/TehmeerAli/Desktop/Tensorflow/Tensorflow for Dummies/chapter8/cifar-10-batches-py/data_batch_'\n",
    "                     + str(file_index + 1), 'rb')\n",
    "    train_dict = pickle.load(train_file, encoding= 'latin1')\n",
    "    train_file.close()\n",
    "    \n",
    "    if train_data is None:\n",
    "        \n",
    "        train_data = np.array(train_dict['data'], float)/255.0\n",
    "        train_labels = train_dict['labels']\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        train_data = np.concatenate((train_data, train_dict['data']), 0)\n",
    "        train_labels = np.concatenate((train_labels, train_dict['labels']), 0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess training data and labels\n",
    "train_data = train_data.reshape([-1, num_channels, image_size, image_size])\n",
    "train_data = train_data.transpose([0, 2, 3, 1])\n",
    "train_labels = np.eye(num_categories)[train_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read CIFAR Test Data\n",
    "test_file = open('C:/Users/TehmeerAli/Desktop/Tensorflow/Tensorflow for Dummies/chapter8/cifar-10-batches-py/test_batch',\n",
    "                 'rb')\n",
    "test_dict = pickle.load(test_file, encoding='latin1')\n",
    "test_file.close()\n",
    "test_data = test_dict['data']\n",
    "test_labels = test_dict['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Preprocess test data and labels\n",
    "test_data = test_data.reshape([-1, num_channels, image_size, image_size])\n",
    "test_data = test_data.transpose([0, 2, 3, 1])\n",
    "test_labels = np.eye(num_categories)[test_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Placeholders for CIFAR images\n",
    "img_holder = tf.placeholder(tf.float32, [None, image_size, image_size, num_channels])\n",
    "lbl_holder = tf.placeholder(tf.float32, [None, num_categories])\n",
    "train = tf.placeholder(tf.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create convolution/pooling layers\n",
    "conv1 = tf.layers.conv2d(img_holder, num_filters, filter_size, padding='same', activation=tf.nn.relu)\n",
    "drop1 = tf.layers.dropout(conv1, keep_prob, training=train)\n",
    "pool1 = tf.layers.max_pooling2d(drop1, 2, 2)\n",
    "\n",
    "conv2 = tf.layers.conv2d(pool1, num_filters, filter_size, padding='same', activation=tf.nn.relu)\n",
    "drop2 = tf.layers.dropout(conv2, keep_prob, training=train)\n",
    "pool2 = tf.layers.max_pooling2d(drop2, 2, 2)\n",
    "\n",
    "conv3 = tf.layers.conv2d(pool2, num_filters, filter_size, padding='same', activation=tf.nn.relu)\n",
    "pool3 = tf.layers.max_pooling2d(conv3, 2, 2)\n",
    "\n",
    "conv4 = tf.layers.conv2d(pool3, num_filters, filter_size, padding='same', activation = tf.nn.relu)\n",
    "drop3 = tf.layers.dropout(conv4, keep_prob, training=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Flatten input data\n",
    "flatten = tf.reshape(drop3, [-1, 512])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create connected layers\n",
    "with tf.contrib.framework.arg_scope(\n",
    "\n",
    "        [tf.contrib.layers.fully_connected],\n",
    "        normalizer_fn = tf.contrib.layers.batch_norm,\n",
    "        normalizer_params = {'is_training': train}):\n",
    "            \n",
    "            fc1 = tf.contrib.layers.fully_connected(flatten, 512)\n",
    "            fc2 = tf.contrib.layers.fully_connected(fc1, num_categories, activation_fn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute loss \n",
    "loss = tf.reduce_mean(\n",
    "\n",
    "        tf.nn.softmax_cross_entropy_with_logits(\n",
    "        logits = fc2, labels=lbl_holder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create optimizer\n",
    "learning_rate = 0.0005\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "# Initialize variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
